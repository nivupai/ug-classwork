{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(text):\n",
    "    letters = list(text.strip())  # remove leading and trailing whitespaces\n",
    "    if len(letters) > 0:\n",
    "        if letters[0] == \"(\":\n",
    "            letters = letters[2:]\n",
    "        if letters[-1] == \" \":\n",
    "            letters = letters[:-1]\n",
    "        # remove punctuation at the end of the sentence\n",
    "        if letters[-1] in ('.', '?', '!', ';'):\n",
    "            letters = letters[:-1]\n",
    "            # remove whitespace after removing punctuation if present\n",
    "            if letters[-1] == ' ':\n",
    "                letters = letters[:-1]\n",
    "        # add start and end of the sentence markers for bigrams\n",
    "        letters = ['<s>'] + letters + ['</s>']\n",
    "    return letters\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    preprocessed_data = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            preprocessed_line = preprocess_sentence(line)\n",
    "            if len(preprocessed_line) > 0:  # check if the line is not empty after preprocessing\n",
    "                preprocessed_data.append(preprocessed_line)\n",
    "    return preprocessed_data\n",
    "\n",
    "eng_train_path = \"../Data/Input/LangId.train.English\"\n",
    "eng_preprocessed = load_and_preprocess_data(eng_train_path)\n",
    "\n",
    "fre_train_path = \"../Data/Input/LangId.train.French\"\n",
    "fre_preprocessed = load_and_preprocess_data(fre_train_path)\n",
    "\n",
    "it_train_path = \"../Data/Input/LangId.train.Italian\"\n",
    "it_preprocessed = load_and_preprocess_data(it_train_path)\n",
    "\n",
    "def preprocess_test_sentence(text):\n",
    "    letters = list(text.strip())  # remove leading and trailing whitespaces\n",
    "    if len(letters) > 0:\n",
    "        if letters[0] == \"(\":\n",
    "            letters = letters[2:]\n",
    "        if letters[-1] == \" \":\n",
    "            letters = letters[:-1]\n",
    "        # remove punctuation at the end of the sentence\n",
    "        if letters[-1] in ('.', '?', '!', ';'):\n",
    "            letters = letters[:-1]\n",
    "            # remove whitespace after removing punctuation if present\n",
    "            if letters[-1] == ' ':\n",
    "                letters = letters[:-1]\n",
    "        # add start and end of the sentence markers for bigrams\n",
    "        letters = ['<s>'] + letters + ['</s>']\n",
    "    return letters\n",
    "\n",
    "def load_and_preprocess_test_data(file_path):\n",
    "    preprocessed_data = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            preprocessed_line = preprocess_test_sentence(line)\n",
    "            if len(preprocessed_line) > 0:  # check if the line is not empty after preprocessing\n",
    "                preprocessed_data.append(preprocessed_line)\n",
    "    return preprocessed_data\n",
    "\n",
    "test_data_path = \"../Data/Validation/LangId.test\"\n",
    "test_preprocessed = load_and_preprocess_test_data(test_data_path)\n",
    "\n",
    "def generate_bigram(data):\n",
    "    bigram = {}\n",
    "    \n",
    "    for sentence in data:  # iterate over each sentence in the data\n",
    "        for idx in range(len(sentence) - 1):  # iterate over each word index in the sentence\n",
    "            current_word = sentence[idx]\n",
    "            next_word = sentence[idx + 1]\n",
    "            \n",
    "            # initialize the bigram dictionary for the current word if it doesn't exist\n",
    "            if current_word not in bigram:\n",
    "                bigram[current_word] = {}\n",
    "            \n",
    "            # increment the count of the next word following the current word\n",
    "            if next_word in bigram[current_word]:\n",
    "                bigram[current_word][next_word] += 1\n",
    "            else:\n",
    "                bigram[current_word][next_word] = 1\n",
    "    \n",
    "    return bigram\n",
    "\n",
    "eng_bigram = generate_bigram(eng_preprocessed)\n",
    "fre_bigram = generate_bigram(fre_preprocessed)\n",
    "it_bigram = generate_bigram(it_preprocessed)\n",
    "\n",
    "def calculate_probability(model, word_prev, word_n):\n",
    "    count = 0\n",
    "    total = 0  \n",
    "\n",
    "    if word_prev in model:\n",
    "        if word_n in model[word_prev]:\n",
    "            count = model[word_prev][word_n]\n",
    "\n",
    "        total = sum(model[word_prev].values())\n",
    "\n",
    "        # calculate the conditional probability P(word_n | word_prev)\n",
    "        if total > 0:\n",
    "            result = count / total\n",
    "        else:\n",
    "            result = 0.0  # handle division by zero\n",
    "    else:\n",
    "        result = 0.0  # if word_prev is not in the model, return probability 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "output_file_path = \"../Data/Output/letterLangId.out\"\n",
    "\n",
    "with open(output_file_path, \"w+\") as output_file:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sentence in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sentence) - 1):\n",
    "            # apply bigram model for english and calculate probability\n",
    "            prob_dict[\"English\"] += calculate_probability(eng_bigram, sentence[word], sentence[word+1])\n",
    "            # apply bigram model for french and calculate probability\n",
    "            prob_dict[\"French\"] += calculate_probability(fre_bigram, sentence[word], sentence[word+1])\n",
    "            # apply bigram model for italian and calculate probability\n",
    "            prob_dict[\"Italian\"] += calculate_probability(it_bigram, sentence[word], sentence[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        output_file.write(str(idx+1) + \" \" + lang + \"\\n\")\n",
    "\n",
    "def read_file(file_path):\n",
    "    data_list = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            # Split each line by whitespace and get the second element\n",
    "            line_parts = line.split()\n",
    "            if len(line_parts) > 1:  # Ensure there are at least two elements in the line\n",
    "                data_list.append(line_parts[1])\n",
    "    return data_list\n",
    "\n",
    "actual_path = \"../Data/Output/letterLangId.out\"\n",
    "expected_path = \"../Data/Validation/labels.sol\"\n",
    "\n",
    "actual_list = read_file(actual_path)\n",
    "expected_list = read_file(expected_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"actual\": actual_list, \"expected\": expected_list}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def check_similarity(actual, expected):\n",
    "    return 1 if actual == expected else 0\n",
    "\n",
    "df[\"similarity_score\"] = df.apply(lambda x: check_similarity(x['actual'], x['expected']), axis=1)\n",
    "\n",
    "accuracy = sum(df[\"similarity_score\"]) / len(df)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
